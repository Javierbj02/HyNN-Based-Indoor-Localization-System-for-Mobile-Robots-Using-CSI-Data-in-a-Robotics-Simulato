{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Noise application.\n",
    "\n",
    "Apply Gaussian noise to the CSI readings of each route. For this, we must adjust for modulus and argument ranges, since data is in polar coordinates. Noise levels are generated by using the normal distribution of Numpy, with a mean=0, and a standard deviation (s.d.) of a percentage of each data range (modulus and argument). This noise is added to the CSI data, clipping to the range of each data.\n",
    "\n",
    "Low noise = 10% of s.d.\n",
    "\n",
    "Medium noise = 20% of s.d.\n",
    "\n",
    "High noise = 30% of s.d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Load route with the CSI data (subsampled)\n",
    "df_8 = pd.read_csv(\"Data/TC1/No noise/ULA_8.csv\")\n",
    "df_16 = pd.read_csv(\"Data/TC1/No noise/ULA_16.csv\")\n",
    "df_32 = pd.read_csv(\"Data/TC1/No noise/ULA_32.csv\")\n",
    "df_64 = pd.read_csv(\"Data/TC1/No noise/ULA_64.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(data, percentage):\n",
    "    \"\"\"\n",
    "    Adds Gaussian noise to the dataset with specified noise level.\n",
    "    \n",
    "    Args:\n",
    "    - data (DataFrame): Original dataset without noise.\n",
    "    - num (float): Noise level factor to multiply with standard deviation.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Dataset with added noise.\n",
    "    \"\"\"\n",
    "    \n",
    "    positionX = data['PositionX']\n",
    "    positionY = data['PositionY']\n",
    "\n",
    "    # Delete position columns\n",
    "    data = data.drop(['PositionX', 'PositionY'], axis=1)\n",
    "\n",
    "    modulus_columns = data.columns[::2]  # Modulus columns\n",
    "    argument_columns = data.columns[1::2]  # Argument columns\n",
    "\n",
    "    range_modulus = 1.0\n",
    "    range_phase = 2 * np.pi\n",
    "\n",
    "    std_dev_mod = percentage * range_modulus\n",
    "    std_dev_arg = percentage * range_phase\n",
    "\n",
    "    # Gaussian noise for modulus\n",
    "    noise_mod = np.random.normal(loc=0, scale=std_dev_mod, size=data[modulus_columns].shape)\n",
    "    # Gaussian noise for argument\n",
    "    noise_arg = np.random.normal(loc=0, scale=std_dev_arg, size=data[argument_columns].shape)\n",
    "\n",
    "    data_noisy = data.copy()\n",
    "    data_noisy[modulus_columns] += noise_mod\n",
    "    data_noisy[argument_columns] += noise_arg\n",
    "\n",
    "    # Clip values to the valid range\n",
    "    data_noisy[modulus_columns] = np.clip(data_noisy[modulus_columns], 0, 1)\n",
    "    data_noisy[argument_columns] = np.clip(data_noisy[argument_columns], -np.pi, np.pi)\n",
    "\n",
    "    # Add position columns\n",
    "    data_noisy['PositionX'] = positionX\n",
    "    data_noisy['PositionY'] = positionY\n",
    "\n",
    "    return data_noisy\n",
    "\n",
    "data = df_8.copy()\n",
    "noisy_data_low = add_noise(data, 0.10)\n",
    "noisy_data_mid = add_noise(data, 0.20)\n",
    "noisy_data_high = add_noise(data, 0.30)\n",
    "\n",
    "# Save noisy data of the routes\n",
    "noisy_data_low.to_csv(\"Data/TC1/Low noise/ULA_8.csv\", index=False)\n",
    "noisy_data_mid.to_csv(\"Data/TC1/Medium noise/ULA_8.csv\", index=False)\n",
    "noisy_data_high.to_csv(\"Data/TC1/High noise/ULA_8.csv\", index=False)\n",
    "\n",
    "data = df_16.copy()\n",
    "noisy_data_low = add_noise(data, 0.10)\n",
    "noisy_data_mid = add_noise(data, 0.20)\n",
    "noisy_data_high = add_noise(data, 0.30)\n",
    "\n",
    "# Save noisy data of the routes\n",
    "noisy_data_low.to_csv(\"Data/TC1/Low noise/ULA_16.csv\", index=False)\n",
    "noisy_data_mid.to_csv(\"Data/TC1/Medium noise/ULA_16.csv\", index=False)\n",
    "noisy_data_high.to_csv(\"Data/TC1/High noise/ULA_16.csv\", index=False)\n",
    "\n",
    "data = df_32.copy()\n",
    "noisy_data_low = add_noise(data, 0.10)\n",
    "noisy_data_mid = add_noise(data, 0.20)\n",
    "noisy_data_high = add_noise(data, 0.30)\n",
    "\n",
    "# Save noisy data of the routes\n",
    "noisy_data_low.to_csv(\"Data/TC1/Low noise/ULA_32.csv\", index=False)\n",
    "noisy_data_mid.to_csv(\"Data/TC1/Medium noise/ULA_32.csv\", index=False)\n",
    "noisy_data_high.to_csv(\"Data/TC1/High noise/ULA_32.csv\", index=False)\n",
    "\n",
    "data = df_64.copy()\n",
    "noisy_data_low = add_noise(data, 0.10)\n",
    "noisy_data_mid = add_noise(data, 0.20)\n",
    "noisy_data_high = add_noise(data, 0.30)\n",
    "\n",
    "# Save noisy data of the routes\n",
    "noisy_data_low.to_csv(\"Data/TC1/Low noise/ULA_64.csv\", index=False)\n",
    "noisy_data_mid.to_csv(\"Data/TC1/Medium noise/ULA_64.csv\", index=False)\n",
    "noisy_data_high.to_csv(\"Data/TC1/High noise/ULA_64.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Load route with the CSI data (subsampled)\n",
    "df_8 = pd.read_csv(\"Data/TC2/No noise/ULA_8.csv\")\n",
    "df_16 = pd.read_csv(\"Data/TC2/No noise/ULA_16.csv\")\n",
    "df_32 = pd.read_csv(\"Data/TC2/No noise/ULA_32.csv\")\n",
    "df_64 = pd.read_csv(\"Data/TC2/No noise/ULA_64.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(data, percentage):\n",
    "    \"\"\"\n",
    "    Adds Gaussian noise to the dataset with specified noise level.\n",
    "    \n",
    "    Args:\n",
    "    - data (DataFrame): Original dataset without noise.\n",
    "    - num (float): Noise level factor to multiply with standard deviation.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Dataset with added noise.\n",
    "    \"\"\"\n",
    "    \n",
    "    positionX = data['PositionX']\n",
    "    positionY = data['PositionY']\n",
    "\n",
    "    # Delete position columns\n",
    "    data = data.drop(['PositionX', 'PositionY'], axis=1)\n",
    "\n",
    "    modulus_columns = data.columns[::2]  # Modulus columns\n",
    "    argument_columns = data.columns[1::2]  # Argument columns\n",
    "\n",
    "    range_modulus = 1.0\n",
    "    range_phase = 2 * np.pi\n",
    "\n",
    "    std_dev_mod = percentage * range_modulus\n",
    "    std_dev_arg = percentage * range_phase\n",
    "\n",
    "    # Gaussian noise for modulus\n",
    "    noise_mod = np.random.normal(loc=0, scale=std_dev_mod, size=data[modulus_columns].shape)\n",
    "    # Gaussian noise for argument\n",
    "    noise_arg = np.random.normal(loc=0, scale=std_dev_arg, size=data[argument_columns].shape)\n",
    "\n",
    "    data_noisy = data.copy()\n",
    "    data_noisy[modulus_columns] += noise_mod\n",
    "    data_noisy[argument_columns] += noise_arg\n",
    "\n",
    "    # Clip values to the valid range\n",
    "    data_noisy[modulus_columns] = np.clip(data_noisy[modulus_columns], 0, 1)\n",
    "    data_noisy[argument_columns] = np.clip(data_noisy[argument_columns], -np.pi, np.pi)\n",
    "\n",
    "    # Add position columns\n",
    "    data_noisy['PositionX'] = positionX\n",
    "    data_noisy['PositionY'] = positionY\n",
    "\n",
    "    return data_noisy\n",
    "\n",
    "data = df_8.copy()\n",
    "noisy_data_low = add_noise(data, 0.10)\n",
    "noisy_data_mid = add_noise(data, 0.20)\n",
    "noisy_data_high = add_noise(data, 0.30)\n",
    "\n",
    "# Save noisy data of the routes\n",
    "noisy_data_low.to_csv(\"Data/TC2/Low noise/ULA_8.csv\", index=False)\n",
    "noisy_data_mid.to_csv(\"Data/TC2/Medium noise/ULA_8.csv\", index=False)\n",
    "noisy_data_high.to_csv(\"Data/TC2/High noise/ULA_8.csv\", index=False)\n",
    "\n",
    "data = df_16.copy()\n",
    "noisy_data_low = add_noise(data, 0.10)\n",
    "noisy_data_mid = add_noise(data, 0.20)\n",
    "noisy_data_high = add_noise(data, 0.30)\n",
    "\n",
    "# Save noisy data of the routes\n",
    "noisy_data_low.to_csv(\"Data/TC2/Low noise/ULA_16.csv\", index=False)\n",
    "noisy_data_mid.to_csv(\"Data/TC2/Medium noise/ULA_16.csv\", index=False)\n",
    "noisy_data_high.to_csv(\"Data/TC2/High noise/ULA_16.csv\", index=False)\n",
    "\n",
    "data = df_32.copy()\n",
    "noisy_data_low = add_noise(data, 0.10)\n",
    "noisy_data_mid = add_noise(data, 0.20)\n",
    "noisy_data_high = add_noise(data, 0.30)\n",
    "\n",
    "# Save noisy data of the routes\n",
    "noisy_data_low.to_csv(\"Data/TC2/Low noise/ULA_32.csv\", index=False)\n",
    "noisy_data_mid.to_csv(\"Data/TC2/Medium noise/ULA_32.csv\", index=False)\n",
    "noisy_data_high.to_csv(\"Data/TC2/High noise/ULA_32.csv\", index=False)\n",
    "\n",
    "data = df_64.copy()\n",
    "noisy_data_low = add_noise(data, 0.10)\n",
    "noisy_data_mid = add_noise(data, 0.20)\n",
    "noisy_data_high = add_noise(data, 0.30)\n",
    "\n",
    "# Save noisy data of the routes\n",
    "noisy_data_low.to_csv(\"Data/TC2/Low noise/ULA_64.csv\", index=False)\n",
    "noisy_data_mid.to_csv(\"Data/TC2/Medium noise/ULA_64.csv\", index=False)\n",
    "noisy_data_high.to_csv(\"Data/TC2/High noise/ULA_64.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Load route with the CSI data (subsampled)\n",
    "df_8 = pd.read_csv(\"Data/TC3/No noise/ULA_8.csv\")\n",
    "df_16 = pd.read_csv(\"Data/TC3/No noise/ULA_16.csv\")\n",
    "df_32 = pd.read_csv(\"Data/TC3/No noise/ULA_32.csv\")\n",
    "df_64 = pd.read_csv(\"Data/TC3/No noise/ULA_64.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(data, percentage):\n",
    "    \"\"\"\n",
    "    Adds Gaussian noise to the dataset with specified noise level.\n",
    "    \n",
    "    Args:\n",
    "    - data (DataFrame): Original dataset without noise.\n",
    "    - num (float): Noise level factor to multiply with standard deviation.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Dataset with added noise.\n",
    "    \"\"\"\n",
    "    \n",
    "    positionX = data['PositionX']\n",
    "    positionY = data['PositionY']\n",
    "\n",
    "    # Delete position columns\n",
    "    data = data.drop(['PositionX', 'PositionY'], axis=1)\n",
    "\n",
    "    modulus_columns = data.columns[::2]  # Modulus columns\n",
    "    argument_columns = data.columns[1::2]  # Argument columns\n",
    "\n",
    "    range_modulus = 1.0\n",
    "    range_phase = 2 * np.pi\n",
    "\n",
    "    std_dev_mod = percentage * range_modulus\n",
    "    std_dev_arg = percentage * range_phase\n",
    "\n",
    "    # Gaussian noise for modulus\n",
    "    noise_mod = np.random.normal(loc=0, scale=std_dev_mod, size=data[modulus_columns].shape)\n",
    "    # Gaussian noise for argument\n",
    "    noise_arg = np.random.normal(loc=0, scale=std_dev_arg, size=data[argument_columns].shape)\n",
    "\n",
    "    data_noisy = data.copy()\n",
    "    data_noisy[modulus_columns] += noise_mod\n",
    "    data_noisy[argument_columns] += noise_arg\n",
    "\n",
    "    # Clip values to the valid range\n",
    "    data_noisy[modulus_columns] = np.clip(data_noisy[modulus_columns], 0, 1)\n",
    "    data_noisy[argument_columns] = np.clip(data_noisy[argument_columns], -np.pi, np.pi)\n",
    "\n",
    "    # Add position columns\n",
    "    data_noisy['PositionX'] = positionX\n",
    "    data_noisy['PositionY'] = positionY\n",
    "\n",
    "    return data_noisy\n",
    "\n",
    "data = df_8.copy()\n",
    "noisy_data_low = add_noise(data, 0.10)\n",
    "noisy_data_mid = add_noise(data, 0.20)\n",
    "noisy_data_high = add_noise(data, 0.30)\n",
    "\n",
    "# Save noisy data of the routes\n",
    "noisy_data_low.to_csv(\"Data/TC3/Low noise/ULA_8.csv\", index=False)\n",
    "noisy_data_mid.to_csv(\"Data/TC3/Medium noise/ULA_8.csv\", index=False)\n",
    "noisy_data_high.to_csv(\"Data/TC3/High noise/ULA_8.csv\", index=False)\n",
    "\n",
    "data = df_16.copy()\n",
    "noisy_data_low = add_noise(data, 0.10)\n",
    "noisy_data_mid = add_noise(data, 0.20)\n",
    "noisy_data_high = add_noise(data, 0.30)\n",
    "\n",
    "# Save noisy data of the routes\n",
    "noisy_data_low.to_csv(\"Data/TC3/Low noise/ULA_16.csv\", index=False)\n",
    "noisy_data_mid.to_csv(\"Data/TC3/Medium noise/ULA_16.csv\", index=False)\n",
    "noisy_data_high.to_csv(\"Data/TC3/High noise/ULA_16.csv\", index=False)\n",
    "\n",
    "data = df_32.copy()\n",
    "noisy_data_low = add_noise(data, 0.10)\n",
    "noisy_data_mid = add_noise(data, 0.20)\n",
    "noisy_data_high = add_noise(data, 0.30)\n",
    "\n",
    "# Save noisy data of the routes\n",
    "noisy_data_low.to_csv(\"Data/TC3/Low noise/ULA_32.csv\", index=False)\n",
    "noisy_data_mid.to_csv(\"Data/TC3/Medium noise/ULA_32.csv\", index=False)\n",
    "noisy_data_high.to_csv(\"Data/TC3/High noise/ULA_32.csv\", index=False)\n",
    "\n",
    "data = df_64.copy()\n",
    "noisy_data_low = add_noise(data, 0.10)\n",
    "noisy_data_mid = add_noise(data, 0.20)\n",
    "noisy_data_high = add_noise(data, 0.30)\n",
    "\n",
    "# Save noisy data of the routes\n",
    "noisy_data_low.to_csv(\"Data/TC3/Low noise/ULA_64.csv\", index=False)\n",
    "noisy_data_mid.to_csv(\"Data/TC3/Medium noise/ULA_64.csv\", index=False)\n",
    "noisy_data_high.to_csv(\"Data/TC3/High noise/ULA_64.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
